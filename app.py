import streamlit as st
import os
import tempfile
import sys
import time

# --- Gemini SDK Imports ---
try:
    from google import genai
    from google.genai import types  # For GenerateContentConfig
    from google.genai.errors import APIError as GeminiAPIError
except ImportError:
    st.error("The 'google-genai' library is not installed. Please install it using 'pip install google-genai'.")
    st.stop()

# Import Whisper model loading
try:
    import whisper
except ImportError:
    st.error("The 'openai-whisper' library is not installed. Please install it using 'pip install openai-whisper'.")
    st.stop()


# --- Configuration and Client Initialization ---
# ‚ùó IMPORTANT: Ensure GEMINI_API_KEY is set in Streamlit secrets
try:
    # Attempt to retrieve API Key from Streamlit secrets
    API_KEY = st.secrets["GEMINI_API_KEY"] 
except KeyError:
    st.error("üö® API Key Error: Please set 'GEMINI_API_KEY' in your Streamlit secrets file or Streamlit Cloud Secrets.")
    st.stop()

try:
    # Initialize the Gemini Client globally
    client = genai.Client(api_key=API_KEY)  
except Exception as e:
    st.error(f"Error initializing AI client. Details: {e}")
    st.stop()
    
# Model name used for text generation
MODEL_NAME = "gemini-2.5-flash" 

# Define language codes for Whisper
LANG_CODE_MY = "my" # ISO code for Burmese/Myanmar


# --- Utility Functions ---

@st.cache_resource
def load_whisper_model():
    """
    Load the Whisper 'base' model once to meet Streamlit Cloud's memory constraints.
    """
    st.info("Loading Whisper **'base'** model... (This initialization happens only once)")
    try:
        # Using 'base' (approx. 1GB RAM) for stability.
        # Set device="cpu" to avoid GPU dependency.
        return whisper.load_model("base", device="cpu") 
    except Exception as e:
        st.error(f"Failed to load Whisper model.")
        st.error("Error Hint: If you see 'Failed to load model', check PyTorch/Whisper installation and memory limits.")
        return None

def transcribe_video_with_whisper(uploaded_file):
    """
    Transcribes the audio from the uploaded video file, automatically detecting language.
    Returns: (transcript, detected_language_code)
    """
    model = load_whisper_model()
    if model is None:
        return None, None
        
    temp_path = None
    try:
        # 1. Save uploaded file to a temporary disk path
        file_suffix = os.path.splitext(uploaded_file.name)[1]
        uploaded_file.seek(0)
        
        with tempfile.NamedTemporaryFile(delete=False, suffix=file_suffix) as tmp_file:
            tmp_file.write(uploaded_file.read())
            temp_path = tmp_file.name

        # 2. Run Whisper on the temporary file
        st.markdown(f"Running Whisper on file: **{uploaded_file.name}**...")
        start_time = time.time()
        
        # Run Whisper (fp16=False for CPU stability)
        result = model.transcribe(temp_path, fp16=False) 
        
        end_time = time.time()
        
        detected_lang = result.get("language", "en") 
        transcript = result["text"].strip()
        
        st.success(f"Language detected by Whisper: **{detected_lang.upper()}**. Transcription completed in {end_time - start_time:.2f} seconds.")

        if len(transcript) < 50:
            st.warning("Whisper completed, but the extracted transcript is too short. Cannot proceed to summarization.")
            return None, None

        return transcript, detected_lang
            
    except Exception as e:
        st.error(f"Whisper Transcription Failed. (Check FFmpeg installation and file integrity)")
        st.error(f"Error Details: {e}")
        return None, None
            
    finally:
        # 3. Clean up the temporary file
        if temp_path and os.path.exists(temp_path):
            os.remove(temp_path)


def summarize_text(transcript_text, detected_lang):
    """
    Summarizes the transcript using the Gemini AI client with language-specific system instructions.
    """
    if not transcript_text or transcript_text.isspace():
        return "Summarization failed: Empty transcript content."
        
    st.info("Step 2/2: Sending transcript to Gemini AI for summarization...")
    
    # --- Dynamic Prompts ---
    if detected_lang == LANG_CODE_MY:
        # Burmese System Instruction 
        system_instruction = (
            "·Äû·ÄÑ·Ä∫·Äû·Ää·Ä∫ ·Äï·Äõ·Ä±·Ä¨·Ä∫·Äñ·ÄÄ·Ä∫·Äõ·Äæ·ÄÑ·Ä∫·Äî·Äö·Ä∫ ·Äó·ÄÆ·Äí·ÄÆ·Äö·Ä≠·ÄØ ·Ä°·Äî·Äæ·ÄÖ·Ä∫·ÄÅ·Äª·ÄØ·Äï·Ä∫·Äû·Ä∞ ·Äñ·Äº·ÄÖ·Ä∫·Äû·Ää·Ä∫·Åã ·Äû·ÄÑ·Ä∫·Åè·Äê·Ä¨·Äù·Äî·Ä∫·Äô·Äæ·Ä¨ ·Ä°·Ä±·Ä¨·ÄÄ·Ä∫·Äï·Ä´ ·Äô·Äº·Äî·Ä∫·Äô·Ä¨·Äó·ÄÆ·Äí·ÄÆ·Äö·Ä≠·ÄØ ·ÄÖ·Ä¨·Äû·Ä¨·Ä∏·ÄÄ·Ä≠·ÄØ ·ÄÅ·ÄΩ·Ä≤·ÄÅ·Äº·Äô·Ä∫·Ä∏·ÄÖ·Ä≠·Äê·Ä∫·Äñ·Äº·Ä¨·Äï·Äº·ÄÆ·Ä∏ ·ÄÜ·ÄΩ·Ä±·Ä∏·Äî·ÄΩ·Ä±·Ä∏·Äë·Ä¨·Ä∏·Äû·Ä±·Ä¨ ·Ä°·Äõ·Ä±·Ä∏·ÄÄ·Äº·ÄÆ·Ä∏·ÄÜ·ÄØ·Ä∂·Ä∏ ·Äû·ÄÑ·Ä∫·Äö·Ä∞·Äô·Äæ·ÄØ·Ä°·ÄÅ·Äª·ÄÄ·Ä∫ ·ÅÖ ·ÄÅ·Äª·ÄÄ·Ä∫·Åä ·Ä°·Äö·Ä∞·Ä°·ÄÜ ·ÅÖ ·ÄÅ·Äª·ÄÄ·Ä∫ ·Äû·Ä≠·ÄØ·Ä∑·Äô·Äü·ÄØ·Äê·Ä∫ ·Ä°·ÄÜ·ÄÑ·Ä∑·Ä∫ ·ÅÖ ·ÄÜ·ÄÑ·Ä∑·Ä∫·ÄÄ·Ä≠·ÄØ ·Äë·ÄØ·Äê·Ä∫·Äî·ÄØ·Äê·Ä∫·Äõ·Äî·Ä∫·Äñ·Äº·ÄÖ·Ä∫·Äû·Ää·Ä∫·Åã ·Äõ·Äú·Äí·Ä∫·ÄÄ·Ä≠·ÄØ ·Äõ·Äæ·ÄÑ·Ä∫·Ä∏·Äú·ÄÑ·Ä∫·Ä∏·Äï·Äº·Äê·Ä∫·Äû·Ä¨·Ä∏·Äû·Ä±·Ä¨ ·Ä°·ÄÅ·Äª·ÄÄ·Ä∫·Ä°·Äú·ÄÄ·Ä∫·ÄÖ·Ä¨·Äõ·ÄÑ·Ä∫·Ä∏ (bullet points) ·Äô·Äª·Ä¨·Ä∏·Äñ·Äº·ÄÑ·Ä∑·Ä∫ ·Äñ·Ä±·Ä¨·Ä∫·Äï·Äº·Äï·Ä´·Åã"
        )
        user_query = f"·ÄÄ·Äª·Ä±·Ä∏·Äá·Ä∞·Ä∏·Äï·Äº·ÄØ·Åç ·Ä°·Ä±·Ä¨·ÄÄ·Ä∫·Äï·Ä´ ·Äó·ÄÆ·Äí·ÄÆ·Äö·Ä≠·ÄØ ·ÄÖ·Ä¨·Äû·Ä¨·Ä∏·ÄÄ·Ä≠·ÄØ ·Ä°·ÄÄ·Äª·Äâ·Ä∫·Ä∏·ÄÅ·Äª·ÄØ·Äï·Ä∫·Äï·Ä±·Ä∏·Äï·Ä´·Åã:\n\n---\n\n{transcript_text}"
        
    else: # Default to English for all other languages
        # English System Instruction 
        system_instruction = (
            "You are a professional video summarizer. Your task is to analyze the following video transcript "
            "and extract the 5 most critical learning points, concepts, or steps discussed. Present the output using clear, concise bullet points."
        )
        user_query = f"Please summarize the following video transcript:\n\n---\n\n{transcript_text}"
    
    # --- Gemini API Call Structure ---
    prompt_contents = [user_query] 

    try:
        response = client.models.generate_content(
            model=MODEL_NAME,
            contents=prompt_contents,
            config=types.GenerateContentConfig( 
                system_instruction=system_instruction, 
                temperature=0.0 # Keep summarization factual
            )
        )
        
        return response.text
        
    except GeminiAPIError as e: 
        st.error(f"Gemini API Call Failed (SDK Error): {e}")
        return "Summarization failed due to API connection error."
    except Exception as e:
        st.error(f"An unexpected error occurred during summarization: {e}")
        return "Summarization failed due to an unexpected error."


# --- Streamlit UI ---
st.set_page_config(page_title="Universal Video/Audio Summarizer (Gemini)", layout="centered")

st.markdown("""
<style>
    /* Custom Styling for aesthetics */
    .stButton>button {
        background-color: #0A66C2; 
        color: white;
        font-size: 16px;
        padding: 10px 24px;
        border-radius: 8px;
        transition: background-color 0.3s;
        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
    }
    .stButton>button:hover {
        background-color: #004182;
    }
    .main-header {
        color: #0A66C2; 
        font-weight: bold;
        text-align: center;
        padding-bottom: 10px;
        border-bottom: 2px solid #e0e0e0;
    }
</style>
""", unsafe_allow_html=True)


st.markdown('<h1 class="main-header">üéôÔ∏è Universal Video/Audio Summarizer (Whisper + Gemini SDK)</h1>', unsafe_allow_html=True)
st.warning("‚ö†Ô∏è **System Note:** Using Whisper **'base'** model for memory compatibility. Burmese transcription accuracy may be lower than with 'large' or 'medium' models.")
st.write("Upload **any** English or **Myanmar (Burmese)** video/audio file to generate a full transcript and a key point summary.")

# File Uploader
ALL_MEDIA_TYPES = [
    "mp4", "mov", "wav", "mp3", "m4a", "mkv", "avi", "flv", "wmv", 
    "ogg", "flac", "wma", "aac", "aiff", "webm"
]

uploaded_file = st.file_uploader(
    "Upload Video or Audio File",
    type=ALL_MEDIA_TYPES,
    accept_multiple_files=False
)

if uploaded_file is not None:
    st.success(f"File uploaded successfully: **{uploaded_file.name}**")
    
    if st.button("Generate Transcript and Summary"):
        
        # 1. Transcription Step
        with st.spinner("Step 1/2: Generating Transcript using Whisper AI..."):
            transcript, detected_lang = transcribe_video_with_whisper(uploaded_file)
            
            if transcript is not None:
                st.subheader("üìù Extracted Transcript (·Äë·ÄØ·Äê·Ä∫·Äö·Ä∞·Äë·Ä¨·Ä∏·Äû·Ä±·Ä¨ ·ÄÖ·Ä¨·Äû·Ä¨·Ä∏)")
                
                # Show the long transcript in an expander
                with st.expander("Click to view full transcript text"):
                    if transcript:
                        st.code(transcript, language="text") 
                    else:
                        st.warning("Transcript is empty or blank. Cannot proceed to summarization.")

                # 2. Summarization Step (Only runs if a valid transcript was returned)
                if transcript:
                    summary = summarize_text(transcript, detected_lang)
                    
                    st.subheader("‚úÖ Summary (Generated by Gemini - ·Ä°·Äî·Äæ·ÄÖ·Ä∫·ÄÅ·Äª·ÄØ·Äï·Ä∫)")
                    st.markdown(summary)
                    
                    if not summary.startswith("Summarization failed"):
                        st.success("Process complete: Transcript generated and Summary extracted.")
                    else:
                        st.error("Process failed during summarization. Check error details above.")
                
            else:
                st.error("Transcription failed. Please ensure the audio quality is clear, the file is valid, and FFmpeg is properly installed on the server.")